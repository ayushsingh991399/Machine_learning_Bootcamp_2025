{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fee633",
   "metadata": {},
   "source": [
    "# Machine Learnig Bootcamp\n",
    "# HomeWork 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e74758",
   "metadata": {},
   "source": [
    "In this homework, we're going to continue working with the lead scoring dataset. You don't need the dataset: we will provide the model for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcda156",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Install uv\n",
    "What's the version of uv you installed?\n",
    "Use --version to find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "759dad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31merror:\u001b[0m unrecognized subcommand '\u001b[33m0.9.5\u001b[0m'\n",
      "\n",
      "\u001b[1m\u001b[32mUsage:\u001b[0m \u001b[1m\u001b[36muv.exe\u001b[0m \u001b[36m[OPTIONS]\u001b[0m \u001b[36m<COMMAND>\u001b[0m\n",
      "\n",
      "For more information, try '\u001b[1m\u001b[36m--help\u001b[0m'.\n"
     ]
    }
   ],
   "source": [
    "uv 0.9.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2626c9",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Use uv to install Scikit-Learn version 1.6.1\n",
    "What's the first hash for Scikit-Learn you get in the lock file?\n",
    "Include the entire string starting with sha256:, don't include quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d721a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.6.1\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ayush\\anaconda3\\envs\\ds_genai\\lib\\site-packages (from scikit-learn==1.6.1) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ayush\\anaconda3\\envs\\ds_genai\\lib\\site-packages (from scikit-learn==1.6.1) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ayush\\anaconda3\\envs\\ds_genai\\lib\\site-packages (from scikit-learn==1.6.1) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ayush\\anaconda3\\envs\\ds_genai\\lib\\site-packages (from scikit-learn==1.6.1) (3.5.0)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.1 MB 2.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.1 MB 2.5 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/11.1 MB 2.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/11.1 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 2.8 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 2.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.8/11.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.7/11.1 MB 3.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.4/11.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 3.2 MB/s  0:00:03\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.7.1\n",
      "    Uninstalling scikit-learn-1.7.1:\n",
      "      Successfully uninstalled scikit-learn-1.7.1\n",
      "Successfully installed scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9df1e",
   "metadata": {},
   "source": [
    "Models\n",
    "We have prepared a pipeline with a dictionary vectorizer and a model.\n",
    "\n",
    "It was trained (roughly) using this code:\n",
    "\n",
    "categorical = ['lead_source']\n",
    "numeric = ['number_of_courses_viewed', 'annual_income']\n",
    "\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "df[numeric] = df[numeric].fillna(0)\n",
    "\n",
    "train_dict = df[categorical + numeric].to_dict(orient='records')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(train_dict, y_train)\n",
    "Note: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download it here.\n",
    "\n",
    "With wget:\n",
    "\n",
    "wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['lead_source']\n",
    "numeric = ['number_of_courses_viewed', 'annual_income']\n",
    "\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "df[numeric] = df[numeric].fillna(0)\n",
    "\n",
    "train_dict = df[categorical + numeric].to_dict(orient='records')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(train_dict, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e88aee",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Let's use the model!\n",
    "\n",
    "Write a script for loading the pipeline with pickle\n",
    "Score this record:\n",
    "{\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}\n",
    "What's the probability that this lead will convert?\n",
    "\n",
    "0.333\n",
    "0.533\n",
    "0.733\n",
    "0.933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5336072702798061"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549bf0e",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "Install FastAPI\n",
    "Write FastAPI code for serving the model\n",
    "Now score this client using requests:\n",
    "url = \"YOUR_URL\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n",
    "What's the probability that this client will get a subscription?\n",
    "\n",
    "0.334\n",
    "0.534\n",
    "0.734\n",
    "0.934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48baa8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'conversion_probability': 0.5340417283801275}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7047d322",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Download the base image agrigorev/zoomcamp-model:2025. You can easily make it by using docker pull command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "45 MB\n",
    "121 MB\n",
    "245 MB\n",
    "330 MB\n",
    "You can get this information when running docker images - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b420393",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY                 TAG       IMAGE ID       CREATED      SIZE\n",
    "agrigorev/zoomcamp-model   2025      14d79fde0bbf   6 days ago   181MB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
